{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a395e0db",
   "metadata": {},
   "source": [
    "# Convert to Dataframe\n",
    "#### Script Purpose\n",
    "In this sample script, we will set up the environment for chatgpt api, then run chatgpt on documents in the sample data. Note that this is a pilot and we welcome all feedback / suggestions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fc428a",
   "metadata": {},
   "source": [
    "#### API Usage\n",
    "Models available: \n",
    "<br>gpt_35_turbo, \n",
    "<br>gpt_4o, \n",
    "<br>gpt_4o_2024_08_06, \n",
    "<br>gpt_4o_mini,\n",
    "<br>o1_mini,\n",
    "<br>o1_preview\n",
    "\n",
    "\n",
    "Limitations:\n",
    "<br>50,000 Tokens/Minute on LLM Access\n",
    "<br>10 Requests/Second across all API endpoints\n",
    "<br>$5 spend/day \n",
    "\n",
    "Cost per 1k tokens:\n",
    "| Model                     | In / 1k Tok | Out / 1k Tok |\n",
    "|:---------------------------|:-------------|:--------------|\n",
    "| gpt_35_turbo     | 0.0000005     | 0.0000015       |\n",
    "| gpt_4o      | 0.000005      | 0.000015       |\n",
    "| gpt_4o_2024_08_06         |  0.0000025       | 0.00001        |\n",
    "| gpt_4o_mini         | 0.00000015       | 0.0000006        |\n",
    "| o1_mini         |  0.000003       | 0.0000012        |\n",
    "| o1_preview         |  0.000015       | 0.00006        |\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3345b97",
   "metadata": {},
   "source": [
    "# Prepare sample data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "377a8fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for parsing data\n",
    "import os\n",
    "import pandas as pd\n",
    "from lxml import etree\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7d6ce1",
   "metadata": {},
   "source": [
    "In the cell below, you can change the corpus directory to the dataset which you are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09720c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently sampling 30 documents.\n"
     ]
    }
   ],
   "source": [
    "# Set corpus to the folder of files you want to use\n",
    "corpus = '/home/ec2-user/SageMaker/data/SAMPLEDATA/'\n",
    "\n",
    "# Read in files\n",
    "input_files = os.listdir(corpus)\n",
    "\n",
    "# Select the number of articles to sample\n",
    "sample_size = 30\n",
    "\n",
    "# Generate a sample of articles\n",
    "try:\n",
    "    sample_input_files = input_files[0:sample_size]\n",
    "\n",
    "except ValueError:\n",
    "    sample_input_files = input_files\n",
    "    \n",
    "print(\"Currently sampling\", len(sample_input_files), \"documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32bcef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to strip html tags from text portion\n",
    "def strip_html_tags(text):\n",
    "    stripped = BeautifulSoup(text).get_text().replace('\\n', ' ').replace('\\\\', '').strip()\n",
    "    return stripped\n",
    "\n",
    "# Retrieve metadata from XML document\n",
    "def getxmlcontent(corpus, file, strip_html=True):\n",
    "    try:\n",
    "        tree = etree.parse(corpus + file)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        if root.find('.//GOID') is not None:\n",
    "            goid = root.find('.//GOID').text\n",
    "        else:\n",
    "            goid = None\n",
    "\n",
    "        if root.find('.//Title') is not None:\n",
    "            title = root.find('.//Title').text\n",
    "        else:\n",
    "            title = None\n",
    "\n",
    "        if root.find('.//NumericDate') is not None:\n",
    "            date = root.find('.//NumericDate').text\n",
    "        else:\n",
    "            date = None\n",
    "            \n",
    "        if root.find('.//PublisherName') is not None:\n",
    "            publisher = root.find('.//PublisherName').text\n",
    "        else:\n",
    "            publisher = None\n",
    "\n",
    "        if root.find('.//FullText') is not None:\n",
    "            text = root.find('.//FullText').text\n",
    "\n",
    "        elif root.find('.//HiddenText') is not None:\n",
    "            text = root.find('.//HiddenText').text\n",
    "\n",
    "        elif root.find('.//Text') is not None:\n",
    "            text = root.find('.//Text').text\n",
    "\n",
    "        else:\n",
    "            text = None\n",
    "\n",
    "        # Strip html from text portion\n",
    "        if text is not None and strip_html == True:\n",
    "            text = strip_html_tags(text)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error while parsing file {file}: {e}\")\n",
    "    \n",
    "    return goid, title, date, publisher, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaa1e177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists to store GOIDs and text\n",
    "goid_list = []\n",
    "date_list = []\n",
    "text_list = []\n",
    "\n",
    "for file in sample_input_files:\n",
    "    \n",
    "    goid, title, date, publisher, text = getxmlcontent(corpus, file, strip_html=True)\n",
    "    \n",
    "    if text is not None:\n",
    "        goid_list.append(goid)\n",
    "        date_list.append(date)\n",
    "        text_list.append(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36064e6",
   "metadata": {},
   "source": [
    "Create Dataframe: This section uses the collected fields to make a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f436fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1323379997</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>About the Authors:  Steffen Dommerich    Contr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671014263</th>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>About the Authors:  Sirinart Techa    Affiliat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2276833012</th>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>About the Authors:  David Benrimoh    Roles Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289270399</th>\n",
       "      <td>2010-02-01</td>\n",
       "      <td>About the Authors:  Vibha Gupta    Contributed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344508114</th>\n",
       "      <td>2012-09-01</td>\n",
       "      <td>About the Authors:  Jing Zhao    Contributed e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304981084</th>\n",
       "      <td>2011-06-01</td>\n",
       "      <td>About the Authors:  Jesse A. Solomon    Affili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2186082215</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>About the Authors:  Jonathan Steinke    Roles ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875828310</th>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>About the Authors:  Björn Hansson    Contribut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325499152</th>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>About the Authors:  Joëlle K. Muhlemann    Aff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764879334</th>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>About the Authors:  Sameh Rabhi    Affiliation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641245449</th>\n",
       "      <td>2014-12-01</td>\n",
       "      <td>About the Authors:  Gabriella Lakatos    * E-m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510768030</th>\n",
       "      <td>2014-03-01</td>\n",
       "      <td>About the Authors:  Matthew J. Perkins    * E-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2486455670</th>\n",
       "      <td>2021-02-01</td>\n",
       "      <td>About the Authors:  Iris Lin    Roles Conceptu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1819118658</th>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>About the Authors:  MiYoung Kwon    * E-mail: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537651600</th>\n",
       "      <td>2014-06-01</td>\n",
       "      <td>About the Authors:  James W. Raich    * E-mail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790065518</th>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>About the Authors:  Alessandro Saccà    * E-ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559783730</th>\n",
       "      <td>2014-09-01</td>\n",
       "      <td>About the Authors:  Selda Aydin    Affiliation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545995269</th>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>About the Authors:  Anthony M. Pedley    Affil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993003439</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>About the Authors:  Zilin Gao    Contributed e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330883140</th>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>About the Authors:  Björn Reinius    * E-mail:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2411076358</th>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>About the Authors:  Lisha Yang    Roles Concep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348115046</th>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>About the Authors:  Lorenzo Marcucci    * E-ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719303908</th>\n",
       "      <td>2015-09-01</td>\n",
       "      <td>About the Authors:  Joshua Chopin    Affiliati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950407702</th>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>About the Authors:  Hiroki Bochimoto    Roles ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616171724</th>\n",
       "      <td>2014-10-01</td>\n",
       "      <td>About the Authors:  Maliheh Hassani    Affilia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292226188</th>\n",
       "      <td>2009-09-01</td>\n",
       "      <td>About the Authors:  Kentaro Yamamoto    * E-ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159700720</th>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>About the Authors:  Miki Tadaishi    Contribut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330900595</th>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>About the Authors:  Weidong Xie    * E-mail: x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2330969465</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>About the Authors:  Michael E. Berens    Contr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700955389</th>\n",
       "      <td>2015-08-01</td>\n",
       "      <td>About the Authors:  Clare E. McElcheran    * E...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Date                                               Text\n",
       "GOID                                                                     \n",
       "1323379997  2012-01-01  About the Authors:  Steffen Dommerich    Contr...\n",
       "1671014263  2015-04-01  About the Authors:  Sirinart Techa    Affiliat...\n",
       "2276833012  2019-08-01  About the Authors:  David Benrimoh    Roles Co...\n",
       "1289270399  2010-02-01  About the Authors:  Vibha Gupta    Contributed...\n",
       "1344508114  2012-09-01  About the Authors:  Jing Zhao    Contributed e...\n",
       "1304981084  2011-06-01  About the Authors:  Jesse A. Solomon    Affili...\n",
       "2186082215  2019-02-01  About the Authors:  Jonathan Steinke    Roles ...\n",
       "1875828310  2017-03-01  About the Authors:  Björn Hansson    Contribut...\n",
       "1325499152  2012-07-01  About the Authors:  Joëlle K. Muhlemann    Aff...\n",
       "1764879334  2016-02-01  About the Authors:  Sameh Rabhi    Affiliation...\n",
       "1641245449  2014-12-01  About the Authors:  Gabriella Lakatos    * E-m...\n",
       "1510768030  2014-03-01  About the Authors:  Matthew J. Perkins    * E-...\n",
       "2486455670  2021-02-01  About the Authors:  Iris Lin    Roles Conceptu...\n",
       "1819118658  2016-09-01  About the Authors:  MiYoung Kwon    * E-mail: ...\n",
       "1537651600  2014-06-01  About the Authors:  James W. Raich    * E-mail...\n",
       "1790065518  2016-05-01  About the Authors:  Alessandro Saccà    * E-ma...\n",
       "1559783730  2014-09-01  About the Authors:  Selda Aydin    Affiliation...\n",
       "1545995269  2014-07-01  About the Authors:  Anthony M. Pedley    Affil...\n",
       "1993003439  2018-01-01  About the Authors:  Zilin Gao    Contributed e...\n",
       "1330883140  2013-02-01  About the Authors:  Björn Reinius    * E-mail:...\n",
       "2411076358  2020-06-01  About the Authors:  Lisha Yang    Roles Concep...\n",
       "1348115046  2012-07-01  About the Authors:  Lorenzo Marcucci    * E-ma...\n",
       "1719303908  2015-09-01  About the Authors:  Joshua Chopin    Affiliati...\n",
       "1950407702  2017-10-01  About the Authors:  Hiroki Bochimoto    Roles ...\n",
       "1616171724  2014-10-01  About the Authors:  Maliheh Hassani    Affilia...\n",
       "1292226188  2009-09-01  About the Authors:  Kentaro Yamamoto    * E-ma...\n",
       "2159700720  2018-12-01  About the Authors:  Miki Tadaishi    Contribut...\n",
       "1330900595  2013-03-01  About the Authors:  Weidong Xie    * E-mail: x...\n",
       "2330969465  2019-12-01  About the Authors:  Michael E. Berens    Contr...\n",
       "1700955389  2015-08-01  About the Authors:  Clare E. McElcheran    * E..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text = pd.DataFrame({'GOID': goid_list, 'Date':date_list, 'Text': text_list})\n",
    "df_text.set_index('GOID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754f46c3",
   "metadata": {},
   "source": [
    "# Using ChatGPT for Information Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69408852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI, OpenAIError\n",
    "import tiktoken\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2b18a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your key to your Academic AI Platform Key\n",
    "client = OpenAI(api_key=\"\",\n",
    "    base_url=\"https://agai-proxy.prod.int.tdmstudio.proquest.com/large-language-models-openai-compatible/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7022a12c",
   "metadata": {},
   "source": [
    "## Approach 1: Explore prompts on a single data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a991e91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the prompt as needed\n",
    "prompt = 'Summarize the text.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009ed80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = df_text['Text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "23649c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The authors Clare E. McElcheran, Benson Yang, Kevan J. T. Anderson, Laleh Golenstani-Rad, and Simon J. Graham have conducted a study on the safety and feasibility of using parallel radiofrequency transmission (pTx) in 3 Tesla magnetic resonance imaging (MRI) to reduce heating in long conductive leads. Such leads are used in deep brain stimulation (DBS) implants to treat neurological disorders. \n",
      "\n",
      "MRI procedures can cause localized heating around these leads due to the electric component of the RF transmission field, posing a risk of tissue damage. The study investigates using pTx with static RF shimming, where different coil elements transmit independently with adjusted amplitudes and phases, to minimize this heating effect while maintaining the necessary B1-field homogeneity for effective imaging.\n",
      "\n",
      "Simulations and experimental validation showed that using pTx with optimized amplitude and phase settings could significantly reduce E-field at the lead tip and along the wire, resulting in reduced specific absorption rate (SAR) and thus minimized heating. Three configurations (two, four, and eight-coil elements) were tested, with the four-element setup showing a marked reduction in heating and maintained imaging quality. \n",
      "\n",
      "Additionally, the study discusses the need to optimize pTx configurations for various wire positions to determine practical implementations in clinical settings. This research demonstrates the potential of pTx to safely enable post-operative MRI for patients with DBS implants, though further optimizations and investigations are necessary to transition the concept to clinical practice.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    # Modify the model here with values from \"Models available\" of API Usage section above         \n",
    "    model='gpt_4o',\n",
    "    messages=[\n",
    "    # Modify the output json format                      \n",
    "        {'role': 'system', 'content': \"You are a helpful assistant.\"},\n",
    "        {'role': 'user', 'content': prompt},\n",
    "        {\"role\": \"user\", \"content\": sample_text}\n",
    "    ],\n",
    ")\n",
    "result = response.choices[0].message.content\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697f995d",
   "metadata": {},
   "source": [
    "## Approach 2: Run ChatGPT on a batch of data using JSON output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76fe8f0",
   "metadata": {},
   "source": [
    "### Create records to keep track of tokens used\n",
    "Run this section to manually update the token usage every 24 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "077dc418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify cost record output to desired save name\n",
    "token_file = '/home/ec2-user/SageMaker/chatgpt_token.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "557259f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call this function if you want to refresh/clear token file and restart the count  \n",
    "def clear_token_record(token_file):\n",
    "    # refresh/clear token file only if you want to restart the count\n",
    "    if os.path.exists(token_file):\n",
    "        os.remove(token_file)\n",
    "        print(f\"{token_file} has been deleted.\")\n",
    "\n",
    "clear_token_record(token_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e542d06a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_token_record(token_file):\n",
    "    # get the previous token usage info and keep adding onto it\n",
    "    if os.path.exists(token_file):\n",
    "        # If the file exists, read the CSV file into a DataFrame\n",
    "        runs_record = pd.read_csv(token_file).reset_index(drop=True)\n",
    "    else:\n",
    "        # If the file does not exist, return an empty DataFrame\n",
    "        runs_record = pd.DataFrame()\n",
    "    \n",
    "    return runs_record\n",
    "\n",
    "# get the previous token usage info and keep adding onto it\n",
    "token_record = get_token_record(token_file)\n",
    "token_record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39cbb8f",
   "metadata": {},
   "source": [
    "### Create records to keep track of all output from chatgpt\n",
    "Run this section to load the previous output and populate it with the new results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8f10a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify result output file to desired save name\n",
    "output_file = '/home/ec2-user/SageMaker/chatgpt_output.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d336c8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call this function if you want to refresh/clear output file and restart the count     \n",
    "def clear_output_record(output_file):\n",
    "    # refresh/clear output file only if you want to restart the count\n",
    "    if os.path.exists(output_file):\n",
    "        os.remove(output_file)\n",
    "        print(f\"{output_file} has been deleted.\")\n",
    "\n",
    "clear_output_record(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "760f4b66",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_output_record(output_file):\n",
    "    # get the previous output info and keep adding onto it\n",
    "    if os.path.exists(output_file):\n",
    "        # If the file exists, read the CSV file into a DataFrame\n",
    "        output_record = pd.read_csv(output_file).reset_index(drop=True)\n",
    "    else:\n",
    "        # If the file does not exist, return an empty DataFrame\n",
    "        output_record = pd.DataFrame()\n",
    "    \n",
    "    return output_record\n",
    "\n",
    "# get the previous output info and keep adding onto it\n",
    "output_record = get_output_record(output_file)\n",
    "output_record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc323495",
   "metadata": {},
   "source": [
    "### Run chatgpt on a batch of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adeeb2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the prompt as needed\n",
    "prompt = 'out put 1 keyword about its topic and methodology for the text given.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9d4905b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting from row 0.\n",
      "Topic: C, Methodology:H, Index:0, Cost: 14367\n",
      "Topic: molting hormones, Methodology:qRT-PCR, Index:1, Cost: 15820\n",
      "Topic: schizophrenia, Methodology:computational modelling, Index:2, Cost: 15372\n",
      "Topic: Mtb-BirA, Methodology:crystallography, Index:3, Cost: 12293\n",
      "Error code: 429 - Application token/minute rate exceeded\n",
      "Will wait for 60 seconds and retry.\n",
      "Topic: cardiovascular disease, Methodology:network-based approach, Index:4, Cost: 13332\n",
      "Topic: ALS, Methodology:mouse models, Index:5, Cost: 19611\n",
      "Topic: agriculture, Methodology:Positive Deviance, Index:6, Cost: 11676\n",
      "Topic: Adipocyte Biology, Methodology:RT-qPCR, Index:7, Cost: 11452\n",
      "Topic: floral_development, Methodology:transcriptome_metabolome_analysis, Index:8, Cost: 16978\n",
      "Topic: leishmaniasis, Methodology:transcriptomic analysis, Index:9, Cost: 15197\n",
      "Topic: emotion, Methodology:behavioral-coding, Index:10, Cost: 16598\n",
      "Topic: food web, Methodology:stable isotope analysis, Index:11, Cost: 10716\n",
      "Error code: 429 - Application token/minute rate exceeded\n",
      "Will wait for 60 seconds and retry.\n",
      "Topic: Fatigue, Methodology:Survey, Index:12, Cost: 9956\n",
      "Topic: SpatialResolution, Methodology:ViewingTime, Index:13, Cost: 15815\n",
      "Topic: forest growth, Methodology:case-study, Index:14, Cost: 11791\n",
      "Topic: biomass, Methodology:image analysis, Index:15, Cost: 9706\n",
      "Topic: AAN, Methodology:genotyping, Index:16, Cost: 10775\n",
      "Error code: 429 - Application token/minute rate exceeded\n",
      "Will wait for 60 seconds and retry.\n",
      "Topic: PCNA, Methodology:fluorescence polarization, Index:17, Cost: 15938\n",
      "Topic: structural balance, Methodology:dynamical equations, Index:18, Cost: 7972\n",
      "Topic: sex-specific gene expression, Methodology:RT-qPCR, Index:19, Cost: 7129\n",
      "Topic: Neurostimulation, Methodology:Whole-cell patch clamp, Index:20, Cost: 21425\n",
      "Topic: muscle contraction, Methodology:diffusion model, Index:21, Cost: 10654\n",
      "Topic: root, Methodology:image-processing, Index:22, Cost: 12529\n",
      "Topic: liver transplantation, Methodology:machine perfusion, Index:23, Cost: 14452\n",
      "Topic: non-consent, Methodology:logistic regression, Index:24, Cost: 7747\n",
      "Topic: Behavioral Interactions, Methodology:Experimental Study, Index:25, Cost: 8696\n",
      "Topic: glucose_metabolism, Methodology:in_vivo_experiment, Index:26, Cost: 6706\n",
      "Error code: 429 - Application token/minute rate exceeded\n",
      "Will wait for 60 seconds and retry.\n",
      "Topic: Inflammation, Methodology:Cell culture, Index:27, Cost: 12497\n",
      "Topic: Gliomas, Methodology:Multimodal analysis, Index:28, Cost: 20870\n",
      "Topic: MRI, Methodology:pTx, Index:29, Cost: 14624\n"
     ]
    }
   ],
   "source": [
    "# lists for chatgpt output\n",
    "topic_list = []\n",
    "methodology_list = []\n",
    "\n",
    "# lists for document date, token cost, and index of the document in original dataset\n",
    "date_list = []\n",
    "cost_list = []\n",
    "index_list = []\n",
    "\n",
    "\n",
    "if output_record.empty:\n",
    "    start_index = 0\n",
    "else:\n",
    "    start_index = output_record['Index'].iloc[-1] + 1\n",
    "print(f\"Starting from row {start_index}.\")\n",
    "stop = False\n",
    "\n",
    "for index, (row_index, row_data) in enumerate(df_text[start_index:].iterrows()):\n",
    "# for index, row in df_text.iterrows():\n",
    "    if stop:\n",
    "        break\n",
    "    text = row_data['Text']\n",
    "    date = row_data['Date']\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                # Modify the model here with values from \"Models available\" of API Usage section above         \n",
    "                model='gpt_4o',\n",
    "                messages=[\n",
    "                # Modify the output json format                      \n",
    "                    {'role': 'system', 'content': \n",
    "                     \"\"\"Return in JSON format: \n",
    "                        {\n",
    "                         'topic': ['topic'], \n",
    "                         'methodology': ['methodology']\n",
    "                        }\n",
    "                    \"\"\"},\n",
    "                    {'role': 'user', 'content': prompt},\n",
    "                    {\"role\": \"user\", \"content\": text}\n",
    "                ],\n",
    "                response_format={\n",
    "                    \"type\": \"json_object\"\n",
    "                }\n",
    "            )\n",
    "            result = response.choices[0].message.content\n",
    "            json_response = json.loads(result)\n",
    "#             print(json_response)\n",
    "            \n",
    "            topic = json_response.get(\"topic\")\n",
    "            if topic is not None:\n",
    "                topic = topic[0]\n",
    "            else:\n",
    "                topic = \"\"\n",
    "                \n",
    "            methodology = json_response.get(\"methodology\")\n",
    "            if methodology is not None:\n",
    "                methodology = methodology[0]\n",
    "            else:\n",
    "                methodology = \"\"\n",
    "                \n",
    "            total_tokens = response.usage.total_tokens\n",
    "            print(f\"Topic: {topic}, Methodology:{methodology}, Index:{index + start_index}, Cost: {total_tokens}\")\n",
    "            \n",
    "            topic_list.append(topic or \"\")\n",
    "            methodology_list.append(methodology or \"\")\n",
    "            date_list.append(date)\n",
    "            cost_list.append(total_tokens)\n",
    "            index_list.append(index + start_index)\n",
    "            \n",
    "            # Break the loop if request is successful\n",
    "            break\n",
    "    \n",
    "        except openai.RateLimitError as e:\n",
    "            error_message = str(e)\n",
    "            if \"Application token/minute rate exceeded\" in error_message:\n",
    "                print(\"Error code: 429 - Application token/minute rate exceeded\")\n",
    "                print(\"Will wait for 60 seconds and retry.\")\n",
    "                time.sleep(60) \n",
    "            elif \"Application cost/day rate exceeded\" in error_message:\n",
    "                print(\"Error code: 429 - Application cost/day rate exceeded\")\n",
    "                print(\"End program.\")\n",
    "                stop = True\n",
    "                break\n",
    "            else:\n",
    "                print(\"Other rate limit exceeded, will wait and retry.\")\n",
    "                time.sleep(60)\n",
    "                \n",
    "        except openai.BadRequestError as e:\n",
    "            print(f\"OpenAI BAD REQUEST error: {e}\")\n",
    "            print(\"Will skip this prompt.\")\n",
    "            # Modify the code below to handle 400 Bad Request errors, which occur when the server cannot process the request due to Azure OpenAI's content management policy. Implement the necessary logic as required for your program. \n",
    "            topic_list.append(\"\")\n",
    "            methodology_list.append(\"\")\n",
    "            date_list.append(date)\n",
    "            cost_list.append(0)\n",
    "            index_list.append(index + start_index)\n",
    "            break\n",
    "            \n",
    "        except OpenAIError as e:\n",
    "            print(f\"HTTP error: {e}\")\n",
    "            stop = True\n",
    "            break\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe8dfba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C',\n",
       " 'molting hormones',\n",
       " 'schizophrenia',\n",
       " 'Mtb-BirA',\n",
       " 'cardiovascular disease',\n",
       " 'ALS',\n",
       " 'agriculture',\n",
       " 'Adipocyte Biology',\n",
       " 'floral_development',\n",
       " 'leishmaniasis',\n",
       " 'emotion',\n",
       " 'food web',\n",
       " 'Fatigue',\n",
       " 'SpatialResolution',\n",
       " 'forest growth',\n",
       " 'biomass',\n",
       " 'AAN',\n",
       " 'PCNA',\n",
       " 'structural balance',\n",
       " 'sex-specific gene expression',\n",
       " 'Neurostimulation',\n",
       " 'muscle contraction',\n",
       " 'root',\n",
       " 'liver transplantation',\n",
       " 'non-consent',\n",
       " 'Behavioral Interactions',\n",
       " 'glucose_metabolism',\n",
       " 'Inflammation',\n",
       " 'Gliomas',\n",
       " 'MRI']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "117f0760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Date</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Methodology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>C</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>molting hormones</td>\n",
       "      <td>qRT-PCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>schizophrenia</td>\n",
       "      <td>computational modelling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2010-02-01</td>\n",
       "      <td>Mtb-BirA</td>\n",
       "      <td>crystallography</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2012-09-01</td>\n",
       "      <td>cardiovascular disease</td>\n",
       "      <td>network-based approach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-06-01</td>\n",
       "      <td>ALS</td>\n",
       "      <td>mouse models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>agriculture</td>\n",
       "      <td>Positive Deviance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>Adipocyte Biology</td>\n",
       "      <td>RT-qPCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>floral_development</td>\n",
       "      <td>transcriptome_metabolome_analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>leishmaniasis</td>\n",
       "      <td>transcriptomic analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>2014-12-01</td>\n",
       "      <td>emotion</td>\n",
       "      <td>behavioral-coding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>2014-03-01</td>\n",
       "      <td>food web</td>\n",
       "      <td>stable isotope analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>2021-02-01</td>\n",
       "      <td>Fatigue</td>\n",
       "      <td>Survey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>2016-09-01</td>\n",
       "      <td>SpatialResolution</td>\n",
       "      <td>ViewingTime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>2014-06-01</td>\n",
       "      <td>forest growth</td>\n",
       "      <td>case-study</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>biomass</td>\n",
       "      <td>image analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>2014-09-01</td>\n",
       "      <td>AAN</td>\n",
       "      <td>genotyping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>PCNA</td>\n",
       "      <td>fluorescence polarization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>structural balance</td>\n",
       "      <td>dynamical equations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>sex-specific gene expression</td>\n",
       "      <td>RT-qPCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>Neurostimulation</td>\n",
       "      <td>Whole-cell patch clamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>muscle contraction</td>\n",
       "      <td>diffusion model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>2015-09-01</td>\n",
       "      <td>root</td>\n",
       "      <td>image-processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>liver transplantation</td>\n",
       "      <td>machine perfusion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>2014-10-01</td>\n",
       "      <td>non-consent</td>\n",
       "      <td>logistic regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>2009-09-01</td>\n",
       "      <td>Behavioral Interactions</td>\n",
       "      <td>Experimental Study</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>glucose_metabolism</td>\n",
       "      <td>in_vivo_experiment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>Inflammation</td>\n",
       "      <td>Cell culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>Gliomas</td>\n",
       "      <td>Multimodal analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>2015-08-01</td>\n",
       "      <td>MRI</td>\n",
       "      <td>pTx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Index        Date                         Topic  \\\n",
       "0       0  2012-01-01                             C   \n",
       "1       1  2015-04-01              molting hormones   \n",
       "2       2  2019-08-01                 schizophrenia   \n",
       "3       3  2010-02-01                      Mtb-BirA   \n",
       "4       4  2012-09-01        cardiovascular disease   \n",
       "5       5  2011-06-01                           ALS   \n",
       "6       6  2019-02-01                   agriculture   \n",
       "7       7  2017-03-01             Adipocyte Biology   \n",
       "8       8  2012-07-01            floral_development   \n",
       "9       9  2016-02-01                 leishmaniasis   \n",
       "10     10  2014-12-01                       emotion   \n",
       "11     11  2014-03-01                      food web   \n",
       "12     12  2021-02-01                       Fatigue   \n",
       "13     13  2016-09-01             SpatialResolution   \n",
       "14     14  2014-06-01                 forest growth   \n",
       "15     15  2016-05-01                       biomass   \n",
       "16     16  2014-09-01                           AAN   \n",
       "17     17  2014-07-01                          PCNA   \n",
       "18     18  2018-01-01            structural balance   \n",
       "19     19  2013-02-01  sex-specific gene expression   \n",
       "20     20  2020-06-01              Neurostimulation   \n",
       "21     21  2012-07-01            muscle contraction   \n",
       "22     22  2015-09-01                          root   \n",
       "23     23  2017-10-01         liver transplantation   \n",
       "24     24  2014-10-01                   non-consent   \n",
       "25     25  2009-09-01       Behavioral Interactions   \n",
       "26     26  2018-12-01            glucose_metabolism   \n",
       "27     27  2013-03-01                  Inflammation   \n",
       "28     28  2019-12-01                       Gliomas   \n",
       "29     29  2015-08-01                           MRI   \n",
       "\n",
       "                          Methodology  \n",
       "0                                   H  \n",
       "1                             qRT-PCR  \n",
       "2             computational modelling  \n",
       "3                     crystallography  \n",
       "4              network-based approach  \n",
       "5                        mouse models  \n",
       "6                   Positive Deviance  \n",
       "7                             RT-qPCR  \n",
       "8   transcriptome_metabolome_analysis  \n",
       "9             transcriptomic analysis  \n",
       "10                  behavioral-coding  \n",
       "11            stable isotope analysis  \n",
       "12                             Survey  \n",
       "13                        ViewingTime  \n",
       "14                         case-study  \n",
       "15                     image analysis  \n",
       "16                         genotyping  \n",
       "17          fluorescence polarization  \n",
       "18                dynamical equations  \n",
       "19                            RT-qPCR  \n",
       "20             Whole-cell patch clamp  \n",
       "21                    diffusion model  \n",
       "22                   image-processing  \n",
       "23                  machine perfusion  \n",
       "24                logistic regression  \n",
       "25                 Experimental Study  \n",
       "26                 in_vivo_experiment  \n",
       "27                       Cell culture  \n",
       "28                Multimodal analysis  \n",
       "29                                pTx  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame()\n",
    "result_df['Index'] = index_list\n",
    "result_df['Date'] = date_list\n",
    "result_df['Topic'] = topic_list\n",
    "result_df['Methodology'] = methodology_list\n",
    "# result_df['Publication'] = publication_list\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddb1d035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>15938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>12529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>14452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>8696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>12497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>14624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Token\n",
       "0   14367\n",
       "1   15820\n",
       "2   15372\n",
       "3   12293\n",
       "4   13332\n",
       "5   19611\n",
       "6   11676\n",
       "7   11452\n",
       "8   16978\n",
       "9   15197\n",
       "10  16598\n",
       "11  10716\n",
       "12   9956\n",
       "13  15815\n",
       "14  11791\n",
       "15   9706\n",
       "16  10775\n",
       "17  15938\n",
       "18   7972\n",
       "19   7129\n",
       "20  21425\n",
       "21  10654\n",
       "22  12529\n",
       "23  14452\n",
       "24   7747\n",
       "25   8696\n",
       "26   6706\n",
       "27  12497\n",
       "28  20870\n",
       "29  14624"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_df = pd.DataFrame()\n",
    "token_df['Token'] = cost_list\n",
    "token_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3357492b",
   "metadata": {},
   "source": [
    "### Save Output to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e563c88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save output to output_file\n",
    "output_record = pd.concat([output_record, result_df], ignore_index=True)\n",
    "output_record.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5752248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save token usage to token_file\n",
    "token_record = pd.concat([token_record, token_df], ignore_index=True)\n",
    "token_record.to_csv(token_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe54792",
   "metadata": {},
   "source": [
    "-- End of approach 2 --"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbf51e1",
   "metadata": {},
   "source": [
    "# Instructions to set up environment\n",
    "\n",
    "### Create Virtual Environment\n",
    "\n",
    "We need to first install openai packages in the environment we want to use. \n",
    "In your workbench, find the **New** button (top right), and select **Terminal** from the drop-down menu.\n",
    "1. Create a new environment: \n",
    "     <br><code>conda create -n chatgpt python=3.11 ipykernel</code>\n",
    "2. Check the if environment is succeefully created: \n",
    "     <br><code>conda env list</code>\n",
    "     <br>you should see the your env(chatgpt) listed under \"# conda environments\"\n",
    "3. Activate the environment: \n",
    "     <br><code>source activate chatgpt</code>\n",
    "4. Register the new environment as a jupyter kernel:\n",
    "     <br><code>python -m ipykernel install --prefix=/home/ec2-user/SageMaker/.jupyter --name chatgpt</code>\n",
    "5. Install openai packages\n",
    "     <br><code>conda install openai pandas lxml bs4 tiktoken</code>\n",
    "     \n",
    "     \n",
    "### Select the Environment for Notebook\n",
    "\n",
    "We switch the environment of current notebook is running to the one we just created.\n",
    "1. Click **Kernel** in the top toolbar of your Jupyter notebook. You will see a dropdown with several menu options.\n",
    "2. In the dropdown menu, mouse over **Change kernel**, and select the name of the environment. It should look like conda_chatgpt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470ca14a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_chatgpt",
   "language": "python",
   "name": "conda_chatgpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
